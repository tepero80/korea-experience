"""
Deep Dive Content Generator
============================
Gemini Deep Research APIë¥¼ ì‚¬ìš©í•˜ì—¬ deep-dive ë“œë˜í”„íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ê³ ,
Nano Banana Proë¡œ ì»¤ë²„ ì´ë¯¸ì§€, Gemini Proë¡œ MDX ë³€í™˜ê¹Œì§€ í•œë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì „ì²´ íŒŒì´í”„ë¼ì¸: Deep Research â†’ ì»¤ë²„ ì´ë¯¸ì§€ â†’ MDX ë³€í™˜ â†’ content/deep-dive/ ì €ì¥

ì‚¬ìš©ë²•:
  # ë‹¤ìŒ ë²ˆí˜¸ ìë™ ê°ì§€ (todo.md ê¸°ë°˜) â€” ì „ì²´ íŒŒì´í”„ë¼ì¸
  python scripts/deep-research.py

  # íŠ¹ì • ë²ˆí˜¸ ì§€ì • â€” ì „ì²´ íŒŒì´í”„ë¼ì¸
  python scripts/deep-research.py --number 37

  # ë²ˆí˜¸ ë²”ìœ„ (ë°°ì¹˜) â€” ì „ì²´ íŒŒì´í”„ë¼ì¸
  python scripts/deep-research.py --from 37 --to 42

  # dry-run (API í˜¸ì¶œ ì—†ì´ í”„ë¡¬í”„íŠ¸ë§Œ í™•ì¸)
  python scripts/deep-research.py --number 37 --dry-run

  # ì´ë¯¸ì§€ë§Œ ìƒì„± (ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ COVER IMAGE íŒŒì‹±)
  python scripts/deep-research.py --number 37 --image-only

  # MDX ë³€í™˜ë§Œ ì‹¤í–‰ (ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ)
  python scripts/deep-research.py --number 37 --convert-only

  # ì´ë¯¸ì§€ ìƒì„± ê±´ë„ˆë›°ê¸°
  python scripts/deep-research.py --number 37 --no-image

  # MDX ë³€í™˜ ê±´ë„ˆë›°ê¸° (ë“œë˜í”„íŠ¸+ì´ë¯¸ì§€ë§Œ)
  python scripts/deep-research.py --number 37 --no-convert

í•„ìš” íŒ¨í‚¤ì§€:
  pip install google-genai python-dotenv Pillow
"""

import argparse
import os
import re
import sys
import time
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
PROJECT_ROOT = Path(__file__).parent.parent
DRAFTS_DIR = PROJECT_ROOT / "content" / "deep-dive-drafts"
TODO_FILE = DRAFTS_DIR / "todo.md"
PROMPT_FILE = DRAFTS_DIR / "PROMPT.md"
IMAGES_DIR = PROJECT_ROOT / "public" / "images" / "deep-dive"

# .env.local ë¡œë“œ
load_dotenv(PROJECT_ROOT / ".env.local")

AGENT_NAME = "deep-research-pro-preview-12-2025"
IMAGE_MODEL = "gemini-3-pro-image-preview"
CONVERT_MODEL = "gemini-3-pro-preview"  # MDX ë³€í™˜ìš©
COVER_MODEL = "gemini-2.5-flash"  # ì»¤ë²„ ìš”ì†Œ ìƒì„±ìš© (backfill)
POLL_INTERVAL = 15  # seconds
MAX_WAIT = 3600     # 60 minutes

# MDX ë³€í™˜ ê²½ë¡œ
DEEP_DIVE_DIR = PROJECT_ROOT / "content" / "deep-dive"
POSTS_DIR = PROJECT_ROOT / "content" / "posts"
README_FILE = DRAFTS_DIR / "README.md"

# ì»¤ë²„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
COVER_IMAGE_TEMPLATE = """Create a professional blog cover image for "Korea Experience", a premium Korea travel and lifestyle website.

LAYOUT REQUIREMENTS (CRITICAL â€” follow exactly):
- Cinematic 16:9 composition (will be used as 1200x630 OG image)
- The vivid editorial scene fills the ENTIRE frame
- Bottom 20%: the scene naturally transitions to a slightly darker tone (no artificial gradient bar, no blur, no frosted glass â€” the scene itself should just be compositionally darker at the bottom)
- Text overlay at bottom-left (with ~40px padding):
  - Main line: "{short_title}" in bold modern sans-serif (like Montserrat or DM Sans), clean white color, medium size (roughly 3-4% of image height â€” NOT too large), with only a very subtle soft shadow for minimal depth
  - Second line below: "KOREA EXPERIENCE" in small caps, letter-spacing wide, semi-transparent white (opacity ~70%), small size, same subtle soft shadow
- Top-right corner: a small rounded pill badge showing "{category}" in white text on a semi-transparent dark background

SCENE DESCRIPTION:
{scene}

INCLUDE THESE ELEMENTS naturally in the scene: {key_objects}

VISUAL STYLE:
- {mood} mood with {color_palette} color palette
- Modern editorial photography with slightly cinematic color grading
- Korean urban/cultural aesthetic feel
- Sharp focus on main subject, subtle depth of field on background
- Professional magazine-quality composition
- If people appear, they must look completely natural and realistic â€” NO cyberpunk, NO futuristic styling, NO neon face paint, NO sci-fi elements on people. People should look like real everyday humans in natural poses and clothing.

TEXT RULES (VERY IMPORTANT):
- "{short_title}" must be spelled exactly, clearly readable, no typos
- "KOREA EXPERIENCE" must be spelled exactly in small caps
- Text should be clean white directly on the image â€” NO heavy dark outlines, NO thick shadows, NO glow effects, NO blur behind text, NO frosted glass, NO semi-transparent boxes, NO gradient overlays behind the text
- Keep text styling minimal and elegant, like a professional magazine cover
- Do NOT add any extra text, watermarks, or stock-photo indicators
- The text should look like it was professionally typeset, not pasted on

The final image should work perfectly as both a social media preview card and a blog article hero image.
"""


def parse_todo() -> dict[int, dict]:
    """todo.mdì—ì„œ ì£¼ì œ ëª©ë¡ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
    items = {}
    with open(TODO_FILE, "r", encoding="utf-8") as f:
        for line in f:
            # íŒ¨í„´: "37. [M] Plastic Surgery Shadow Doctors"
            m = re.match(r"(\d+)\.\s*\[([A-Z])\]\s*(.+)", line.strip())
            if m:
                num = int(m.group(1))
                cat_code = m.group(2)
                topic = m.group(3).strip()
                cat_map = {
                    "M": "Medical Tourism",
                    "T": "Travel & Tourism",
                    "K": "K-Culture",
                    "L": "Living in Korea",
                    "F": "Food & Dining",
                    "S": "Shopping & K-Beauty",
                }
                items[num] = {
                    "number": num,
                    "code": cat_code,
                    "topic": topic,
                    "category": cat_map.get(cat_code, "Unknown"),
                }
    return items


def find_next_number(items: dict) -> int | None:
    """ë“œë˜í”„íŠ¸ í´ë”ì—ì„œ ì•„ì§ ë‚´ìš©ì´ ì±„ì›Œì§€ì§€ ì•Šì€ ê°€ì¥ ì‘ì€ ë²ˆí˜¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    for num in sorted(items.keys()):
        txt_files = list(DRAFTS_DIR.glob(f"{num}.*"))
        if not txt_files:
            return num
        # íŒŒì¼ì´ ìˆì–´ë„ ë¹„ì–´ìˆìœ¼ë©´ ì•„ì§ í•  ê²ƒ
        for f in txt_files:
            if f.suffix == ".txt" and f.stat().st_size < 100:
                return num
    return None


def build_prompt(topic: str, category: str) -> str:
    """PROMPT.md í…œí”Œë¦¿ì„ ì½ê³  ì£¼ì œë¥¼ ì‚½ì…í•©ë‹ˆë‹¤."""
    with open(PROMPT_FILE, "r", encoding="utf-8") as f:
        template = f.read()

    # PROMPT.mdì˜ [10 social rules...] ë¶€ë¶„ì„ ì‹¤ì œ ì£¼ì œë¡œ êµì²´
    prompt = re.sub(
        r"\[.*?\]",
        f"[{topic}]",
        template,
        count=1,  # ì²« ë²ˆì§¸ ëŒ€ê´„í˜¸ë§Œ êµì²´
    )

    # ì¹´í…Œê³ ë¦¬ íŒíŠ¸ ì¶”ê°€ (í”„ë¡¬í”„íŠ¸ ë§ˆì§€ë§‰ì—)
    prompt += f"\n\n---\n## CATEGORY HINT\nThis topic belongs to: **{category}**\n"
    prompt += f"Topic to research: **{topic}**\n"

    return prompt


def get_draft_filepath(num: int, items: dict) -> Path:
    """ë“œë˜í”„íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ ê²½ë¡œ ì‚¬ìš©
    existing = list(DRAFTS_DIR.glob(f"{num}.*txt"))
    if existing:
        return existing[0]

    # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    item = items[num]
    filename = f"{num}. [{item['code']}] {item['topic']}.txt"
    return DRAFTS_DIR / filename


def run_deep_research(prompt: str, api_key: str) -> str:
    """Deep Research APIë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from google import genai

    client = genai.Client(api_key=api_key)

    print("ğŸ”¬ Deep Research ì‹œì‘...")
    print(f"   ì—ì´ì „íŠ¸: {AGENT_NAME}")

    interaction = client.interactions.create(
        input=prompt,
        agent=AGENT_NAME,
        background=True,
    )

    interaction_id = interaction.id
    print(f"   Interaction ID: {interaction_id}")

    start_time = time.time()
    last_status = None

    while True:
        elapsed = time.time() - start_time
        if elapsed > MAX_WAIT:
            raise TimeoutError(f"â° {MAX_WAIT}ì´ˆ ì´ˆê³¼. Interaction ID: {interaction_id}")

        interaction = client.interactions.get(interaction_id)
        status = interaction.status

        if status != last_status:
            mins = int(elapsed // 60)
            secs = int(elapsed % 60)
            print(f"   [{mins:02d}:{secs:02d}] ìƒíƒœ: {status}")
            last_status = status

        if status == "completed":
            result = interaction.outputs[-1].text
            mins = int(elapsed // 60)
            secs = int(elapsed % 60)
            print(f"âœ… ì™„ë£Œ! ({mins}ë¶„ {secs}ì´ˆ, {len(result):,}ì)")
            return result

        elif status in ("failed", "cancelled"):
            raise RuntimeError(f"âŒ ì‹¤íŒ¨: {status}")

        time.sleep(POLL_INTERVAL)


def run_deep_research_streaming(prompt: str, api_key: str) -> str:
    """Deep Research APIë¥¼ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    from google import genai

    client = genai.Client(api_key=api_key)

    print("ğŸ”¬ Deep Research ì‹œì‘ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)...")
    print(f"   ì—ì´ì „íŠ¸: {AGENT_NAME}")

    stream = client.interactions.create(
        input=prompt,
        agent=AGENT_NAME,
        background=True,
        stream=True,
        agent_config={
            "type": "deep-research",
            "thinking_summaries": "auto",
        },
    )

    interaction_id = None
    full_text = []
    start_time = time.time()

    for chunk in stream:
        if chunk.event_type == "interaction.start":
            interaction_id = chunk.interaction.id
            print(f"   Interaction ID: {interaction_id}")

        if chunk.event_type == "content.delta":
            if chunk.delta.type == "text":
                full_text.append(chunk.delta.text)
                # ì§„í–‰ë¥  í‘œì‹œ (ì ìœ¼ë¡œ)
                print(".", end="", flush=True)
            elif chunk.delta.type == "thought_summary":
                elapsed = time.time() - start_time
                mins = int(elapsed // 60)
                secs = int(elapsed % 60)
                thought = chunk.delta.content.text[:80]
                print(f"\n   [{mins:02d}:{secs:02d}] ğŸ’­ {thought}...")

        elif chunk.event_type == "interaction.complete":
            elapsed = time.time() - start_time
            mins = int(elapsed // 60)
            secs = int(elapsed % 60)
            result = "".join(full_text)
            print(f"\nâœ… ì™„ë£Œ! ({mins}ë¶„ {secs}ì´ˆ, {len(result):,}ì)")
            return result

    # ìŠ¤íŠ¸ë¦¼ì´ ëë‚¬ì§€ë§Œ complete ì´ë²¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš° â€” í´ë§ìœ¼ë¡œ ì „í™˜
    if interaction_id:
        print("\nâš ï¸ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ â€” í´ë§ìœ¼ë¡œ ì „í™˜...")
        return _poll_for_result(client, interaction_id, start_time)

    raise RuntimeError("âŒ ìŠ¤íŠ¸ë¦¼ì—ì„œ ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def _poll_for_result(client, interaction_id: str, start_time: float) -> str:
    """ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ ì‹œ í´ë§ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤."""
    while True:
        elapsed = time.time() - start_time
        if elapsed > MAX_WAIT:
            raise TimeoutError(f"â° {MAX_WAIT}ì´ˆ ì´ˆê³¼.")

        interaction = client.interactions.get(interaction_id)

        if interaction.status == "completed":
            result = interaction.outputs[-1].text
            mins = int(elapsed // 60)
            secs = int(elapsed % 60)
            print(f"âœ… ì™„ë£Œ! ({mins}ë¶„ {secs}ì´ˆ, {len(result):,}ì)")
            return result
        elif interaction.status in ("failed", "cancelled"):
            raise RuntimeError(f"âŒ ì‹¤íŒ¨: {interaction.status}")

        time.sleep(POLL_INTERVAL)


# ============================================================
# ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„± (Nano Banana Pro)
# ============================================================

def parse_cover_image_elements(draft_text: str) -> dict | None:
    """ë“œë˜í”„íŠ¸ì—ì„œ COVER IMAGE ì„¹ì…˜ì˜ ìš”ì†Œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    # COVER IMAGE ì„¹ì…˜ ì°¾ê¸°
    cover_match = re.search(
        r"##\s*COVER\s*IMAGE.*?\n(.*?)(?=\n##\s|\Z)",
        draft_text,
        re.DOTALL | re.IGNORECASE,
    )
    if not cover_match:
        # ## í—¤ë” ì—†ì´ plain textë¡œ ëœ ê²½ìš°ë„ ì‹œë„
        cover_match = re.search(
            r"COVER\s*IMAGE\s*\n(.*?)(?=\n(?:OPTIONAL|SOURCES|ARTICLE|LOCATIONS|PRICE|KEY STAT|ROUTE)|\Z)",
            draft_text,
            re.DOTALL | re.IGNORECASE,
        )
    if not cover_match:
        return None

    section = cover_match.group(1)

    def extract_field(name: str) -> str:
        """**Name:** value ë˜ëŠ” Name: value íŒ¨í„´ ì¶”ì¶œ"""
        patterns = [
            rf"\*\*{name}:\*\*\s*(.+?)(?=\n\*\*|\n---|\Z)",
            rf"{name}:\s*(.+?)(?=\n[A-Z]|\n\*\*|\n---|\Z)",
        ]
        for pat in patterns:
            m = re.search(pat, section, re.IGNORECASE | re.DOTALL)
            if m:
                return m.group(1).strip().strip('"\'')
        return ""

    short_title = extract_field("Short Title")
    scene = extract_field("Scene")
    key_objects = extract_field("Key Objects")
    mood = extract_field("Mood")
    color_palette = extract_field("Color Palette")

    if not scene:
        return None

    return {
        "short_title": short_title or "Korea Guide",
        "scene": scene,
        "key_objects": key_objects or "Korean cityscape",
        "mood": mood or "vibrant",
        "color_palette": color_palette or "warm tones, soft blue",
    }


def generate_cover_image(
    elements: dict,
    category: str,
    slug: str,
    api_key: str,
) -> Path | None:
    """Nano Banana Proë¡œ ì»¤ë²„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    prompt = COVER_IMAGE_TEMPLATE.format(
        short_title=elements["short_title"],
        category=category,
        scene=elements["scene"],
        key_objects=elements["key_objects"],
        mood=elements["mood"],
        color_palette=elements["color_palette"],
    )

    print(f"\nğŸ¨ ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    print(f"   ëª¨ë¸: {IMAGE_MODEL}")
    print(f"   Short Title: \"{elements['short_title']}\"")
    print(f"   Scene: {elements['scene'][:80]}...")

    try:
        response = client.models.generate_content(
            model=IMAGE_MODEL,
            contents=[prompt],
            config=types.GenerateContentConfig(
                response_modalities=["IMAGE"],
                image_config=types.ImageConfig(
                    aspect_ratio="16:9",
                    image_size="2K",
                ),
            ),
        )

        # ì´ë¯¸ì§€ ì €ì¥ (genai Image â†’ ì„ì‹œ PNG â†’ Pillow â†’ WebP)
        from PIL import Image as PILImage
        import tempfile
        IMAGES_DIR.mkdir(parents=True, exist_ok=True)
        output_path = IMAGES_DIR / f"{slug}.webp"

        for part in response.parts:
            if part.inline_data is not None:
                image = part.as_image()
                # genai ImageëŠ” íŒŒì¼ ê²½ë¡œë§Œ ì§€ì› â†’ ì„ì‹œ PNGë¡œ ì €ì¥ í›„ WebP ë³€í™˜
                with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
                    tmp_path = tmp.name
                image.save(tmp_path)
                pil_img = PILImage.open(tmp_path)
                pil_img.save(str(output_path), format="WEBP", quality=85)
                Path(tmp_path).unlink(missing_ok=True)
                print(f"âœ… ì»¤ë²„ ì´ë¯¸ì§€ ì €ì¥: {output_path.relative_to(PROJECT_ROOT)}")
                return output_path

        print("âš ï¸  ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ì‘ë‹µì— ì´ë¯¸ì§€ ì—†ìŒ)")
        return None

    except Exception as e:
        print(f"âš ï¸  ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def make_slug(topic: str) -> str:
    """í† í”½ ì´ë¦„ì—ì„œ íŒŒì¼ëª…ìš© slugë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    slug = topic.lower().strip()
    slug = re.sub(r"[^a-z0-9\s-]", "", slug)
    slug = re.sub(r"[\s_]+", "-", slug)
    slug = re.sub(r"-+", "-", slug).strip("-")
    # ê¸¸ì´ ì œí•œ
    if len(slug) > 60:
        slug = slug[:60].rsplit("-", 1)[0]
    return slug


# ============================================================
# MDX ë³€í™˜ (Gemini Pro)
# ============================================================

VALID_COMPONENTS = [
    "KeyTakeaways", "FAQAccordion", "ExpertTip", "InfoBox", "StepGuide",
    "ProsCons", "PriceTable", "StatCard", "QuickFacts", "ComparisonTable",
    "LocationCard", "Timeline", "DualismRoute",
]

ARRAY_PROPS = [
    "highlights", "points", "pros", "cons", "items", "facts",
    "stats", "steps", "rows", "headers", "stops",
]


def get_existing_slugs() -> list[str]:
    """content/posts/ + content/deep-dive/ ì˜ ê¸°ì¡´ slug ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    slugs = []
    for d in [POSTS_DIR, DEEP_DIVE_DIR]:
        if d.exists():
            for f in d.glob("*.md"):
                slugs.append(f.stem)
    return sorted(set(slugs))


def get_next_deep_dive_order() -> int:
    """í˜„ì¬ ê°€ì¥ ë†’ì€ deepDiveOrder + 1ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    max_order = 0
    if DEEP_DIVE_DIR.exists():
        for f in DEEP_DIVE_DIR.glob("*.md"):
            content = f.read_text(encoding="utf-8")[:500]
            m = re.search(r"deepDiveOrder:\s*(\d+)", content)
            if m:
                max_order = max(max_order, int(m.group(1)))
    return max_order + 1


def build_conversion_prompt(draft_text: str, category: str, slug: str, image_path: str | None, today: str) -> str:
    """ë“œë˜í”„íŠ¸ë¥¼ MDXë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    existing_slugs = get_existing_slugs()
    deep_dive_order = get_next_deep_dive_order()

    # ìŠ¬ëŸ¬ê·¸ ëª©ë¡ (ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 20ê°œ)
    slug_lines = "\n".join(f"  /blog/{s}" for s in existing_slugs[:100])

    image_frontmatter = ""
    if image_path:
        image_frontmatter = f'image: "{image_path}"'

    return f"""You are an expert MDX content converter for the Korea Experience blog.
Convert the following Deep Research draft into a production-ready MDX blog post.

CRITICAL RULES:
1. Output ONLY the MDX content. Start directly with --- for frontmatter.
2. Do NOT wrap output in code blocks. No ```markdown or ```mdx.
3. English only â€” no Korean characters in the output.
4. All content from the draft must be preserved â€” do not omit information.

FRONTMATTER (exact format):
---
title: "[SEO title - MUST be â‰¤70 characters, include main keyword]"
date: {today}
excerpt: "[Compelling summary - MUST be â‰¤160 characters, include specific data]"
category: {category}
author: Korea Experience Team
deepDive: true
deepDiveOrder: {deep_dive_order}
{image_frontmatter}
---

TITLE RULES:
- MUST be 70 characters or fewer
- Use natural sentence case (only capitalize first word, proper nouns, acronyms)
- The draft TITLE is usually too long â€” rewrite it shorter while keeping the main keyword

EXCERPT RULES:
- MUST be 160 characters or fewer
- Include specific data points (prices, percentages, year)
- Do NOT use colons (:) inside the excerpt

STRUCTURE (follow this order):

1. Opening paragraph: Direct answer to what the reader is searching for.
   Then: **The short answer:** [1-2 sentence bold summary]

2. <KeyTakeaways> â€” from KEY TAKEAWAYS section
   ```jsx
   <KeyTakeaways
     points={{["point 1", "point 2", "point 3"]}}
     readTime={{CALCULATED_READ_TIME}}
     lastUpdated="{today}"
   />
   ```
   readTime: 3000-4000 words=10-12, 4000-5500=12-15, 5500-7000=15-18, 7000+=18-20

3. <QuickFacts> â€” from QUICK FACTS section
   ```jsx
   <QuickFacts title="..." facts={{[{{ label: "...", value: "...", icon: "..." }}]}} columns={{3}} />
   ```

4. Body sections with ## H2 headings (from ARTICLE BODY)

5. <Timeline> â€” from TIMELINE section (embed in relevant body section)
   ```jsx
   <Timeline title="..." items={{[{{ time: "...", title: "...", description: "...", icon: "..." }}]}} />
   ```

6. <ComparisonTable> â€” from COMPARISON TABLE section
   ```jsx
   <ComparisonTable title="..." headers={{["Feature", "A", "B"]}} rows={{[{{ feature: "...", option1: "...", option2: "..." }}]}} />
   ```
   Key names: feature, option1, option2, option3 (fixed names!)

7. <ProsCons> â€” from PROS AND CONS section
   ```jsx
   <ProsCons title="..." pros={{["..."]}} cons={{["..."]}} variant="cards" />
   ```

8. <StepGuide> â€” from STEP-BY-STEP GUIDE section
   ```jsx
   <StepGuide title="..." totalTime="..." difficulty="easy" steps={{[{{ title: "...", description: "...", tip: "..." }}]}} />
   ```
   âš ï¸ difficulty MUST be lowercase: "easy", "medium", or "hard"

9. <ExpertTip> â€” from EXPERT TIP section (Deep-Dive style, self-closing)
   ```jsx
   <ExpertTip name="..." role="..." experience="..." quote="..." />
   ```

10. <InfoBox> â€” from WARNINGS AND TIPS section
    ```jsx
    <InfoBox type="tip" title="Pro Tip: ...">content</InfoBox>
    <InfoBox type="warning" title="...">content</InfoBox>
    <InfoBox type="arc-free" title="No Korean Phone/ARC? Here's What To Do">solution</InfoBox>
    ```
    âš ï¸ arc-free InfoBox is MANDATORY in every article!

11. OPTIONAL â€” <LocationCard> if LOCATIONS section exists:
    ```jsx
    <LocationCard name="..." nameKo="..." type="..." address="..." hours="..." priceRange="..." rating={{4.5}} transit="..." highlights={{["..."]}} tip="..." />
    ```

12. OPTIONAL â€” <PriceTable> if PRICE TABLE section exists:
    ```jsx
    <PriceTable title="..." variant="dualism" items={{[{{ name: "...", price: "...", tag: "luxury", description: "..." }}]}} />
    ```

13. OPTIONAL â€” <StatCard> if KEY STATISTICS section exists:
    ```jsx
    <StatCard title="..." variant="gradient" stats={{[{{ value: "...", label: "...", icon: "..." }}]}} source="..." />
    ```

14. OPTIONAL â€” <DualismRoute> if ROUTE COMPARISON section exists (Travel only):
    ```jsx
    <DualismRoute title="..." area="..." totalBudget={{{{ luxury: "...", budget: "..." }}}} totalTime="..." stops={{[...]}} recommendation="..." />
    ```
    âš ï¸ totalBudget uses double curly braces!

15. <FAQAccordion> â€” from FAQ section (MANDATORY, 5+ questions)
    ```jsx
    <FAQAccordion items={{[{{ question: "...", answer: "..." }}]}} />
    ```

16. Conclusion section with action plan. End with encouraging closing.

17. --- (horizontal rule)
    ## Sources
    - [Source Name](URL) - Brief description of what data came from this source
    Rules for Sources:
    - Select only 5-8 HIGH-QUALITY sources (government sites, major news outlets, academic papers, official organizations)
    - EXCLUDE Reddit, Wikipedia, YouTube, forums, individual clinic websites, and travel blogs
    - Each source MUST have a "- description" explaining what data was referenced
    - Format: `- [Publication Name](URL) - What specific data or facts came from this source`

INTERNAL LINKS (MANDATORY 3-5):
Embed naturally throughout the body using: [anchor text](/blog/slug)
ONLY use slugs from this list:
{slug_lines}

LATEX CONVERSION (CRITICAL):
- $â‚©10,320$ â†’ â‚©10,320
- $42\\%$ â†’ 42%
- $\\approx$ â†’ ~
- $3,000 - $7,000 â†’ $3,000â€“$7,000 (use en-dash for ranges, keep $ for USD)
- $$formula$$ â†’ plain text explanation
- Remove ALL LaTeX $ delimiters and commands, but KEEP currency $ signs

ICON RULE (CRITICAL):
- ALL icon props MUST use emoji characters, NOT text strings
- CORRECT: icon: "ğŸ’°"  icon: "ğŸ“…"  icon: "ğŸ¥"
- WRONG:   icon: "money"  icon: "calendar"  icon: "hospital"

JSX RULES:
- Array props MUST use curly braces: points={{["a", "b"]}}
- Boolean: rating={{4.5}} verified={{true}}
- No double quotes inside strings â€” use single quotes: "The 'best' option"
- All components must be properly closed (self-closing /> or matching </Tag>)
- HEADING hierarchy: use ## H2 for sections, ### H3 for subsections only

MINIMUM REQUIREMENTS:
- At least 3,000 words of body content
- At least 5-7 visual components
- At least 4-6 ## H2 sections
- KeyTakeaways right after intro (MANDATORY)
- FAQAccordion near the end (MANDATORY)
- InfoBox type="arc-free" (MANDATORY)

---

DRAFT TO CONVERT:

{draft_text}
"""


def sanitize_mdx(content: str) -> tuple[str, list[str]]:
    """MDX ë‚´ìš©ì„ ìë™ ê²€ì¦/ìˆ˜ì •í•©ë‹ˆë‹¤."""
    fixes = []

    # 0. ì½”ë“œë¸”ë¡ ë˜í¼ ì œê±°
    if content.startswith("```markdown") or content.startswith("```mdx") or content.startswith("```"):
        content = re.sub(r"^```(?:markdown|mdx)?\n", "", content)
        content = re.sub(r"\n```\s*$", "", content)
        fixes.append("Removed code block wrapper")

    # 1. difficulty ëŒ€ì†Œë¬¸ì ìˆ˜ì •
    def fix_difficulty(m):
        val = m.group(1)
        lower = val.lower()
        if lower != val:
            fixes.append(f'difficulty="{val}" â†’ difficulty="{lower}"')
        return f'difficulty="{lower}"'

    content = re.sub(r'difficulty="(Easy|Medium|Hard|EASY|MEDIUM|HARD)"', fix_difficulty, content, flags=re.IGNORECASE)

    # 2. ë°°ì—´ propsì— {} ëˆ„ë½: highlights=["..."] â†’ highlights={["..."]}
    array_pat = r'(' + '|'.join(ARRAY_PROPS) + r')\s*=\s*\['
    def fix_array(m):
        attr = m.group(1)
        fixes.append(f"{attr}=[] â†’ {attr}={{[]}}")
        return f"{attr}={{["
    content = re.sub(array_pat, fix_array, content)

    # 3. ì˜ëª»ëœ ë‹«ëŠ” íƒœê·¸ ìˆ˜ì •
    def fix_closing_tag(m):
        tag = m.group(1)
        if tag in VALID_COMPONENTS:
            return m.group(0)
        for valid in VALID_COMPONENTS:
            if valid.lower() in tag.lower() or tag.lower() in valid.lower():
                fixes.append(f"</{tag}> â†’ </{valid}>")
                return f"</{valid}>"
        return m.group(0)

    content = re.sub(r"</([A-Z][a-zA-Z]+)>", fix_closing_tag, content)

    # 4. LaTeX ì”ì—¬ ì œê±° (í†µí™” $ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    # LaTeX ìˆ˜ì‹ì€ ë³´í†µ \ëª…ë ¹ì–´ë¥¼ í¬í•¨í•˜ê±°ë‚˜ â‚© ê°™ì€ í†µí™”ê¸°í˜¸ë¥¼ ê°ìŒˆ
    latex_inline = re.findall(r"\$[^$]*\\[a-zA-Z][^$]*\$|\$â‚©[\d,]+\$", content)
    for expr in latex_inline:
        inner = expr.strip("$")
        # ê°„ë‹¨í•œ ë³€í™˜
        clean = inner.replace("\\%", "%").replace("\\approx", "~").replace("\\times", "Ã—")
        clean = re.sub(r"\\frac\{([^}]+)\}\{([^}]+)\}", r"\1/\2", clean)
        clean = re.sub(r"\\[a-zA-Z]+", "", clean).strip()
        if clean != inner:
            content = content.replace(expr, clean)
            fixes.append(f"LaTeX: {expr[:30]} â†’ {clean[:30]}")

    # 5. ë‚´ë¶€ ë§í¬ ê²€ì¦
    existing_slugs = set(get_existing_slugs())

    def fix_link(m):
        anchor = m.group(1)
        slug = m.group(2)
        if slug in existing_slugs:
            return m.group(0)
        # ìœ ì‚¬ ìŠ¬ëŸ¬ê·¸ ì°¾ê¸°
        slug_words = [w for w in slug.split("-") if len(w) > 3]
        for s in existing_slugs:
            if slug_words and sum(1 for w in slug_words if w in s) >= max(1, len(slug_words) * 0.75):
                fixes.append(f"Link fixed: /blog/{slug} â†’ /blog/{s}")
                return f"[{anchor}](/blog/{s})"
        fixes.append(f"Link removed (no match): /blog/{slug}")
        return anchor

    content = re.sub(r"\[([^\]]+)\]\(/blog/([a-z0-9-]+)\)", fix_link, content)

    # 6. ì†ì„±ëª…ì— ì (.) í¬í•¨ ì œê±°
    content = re.sub(r"^(\s+)(\w+)\.\s*=", lambda m: f"{m.group(1)}{m.group(2)}=", content, flags=re.MULTILINE)

    return content, fixes


def convert_to_mdx(
    draft_text: str,
    category: str,
    slug: str,
    image_path: str | None,
    api_key: str,
) -> str | None:
    """Gemini Proë¥¼ ì‚¬ìš©í•˜ì—¬ ë“œë˜í”„íŠ¸ë¥¼ MDXë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    today = time.strftime("%Y-%m-%d")
    prompt = build_conversion_prompt(draft_text, category, slug, image_path, today)

    print(f"\nğŸ“ MDX ë³€í™˜ ì¤‘...")
    print(f"   ëª¨ë¸: {CONVERT_MODEL}")
    print(f"   í”„ë¡¬í”„íŠ¸: {len(prompt):,}ì")

    try:
        response = client.models.generate_content(
            model=CONVERT_MODEL,
            contents=[prompt],
            config=types.GenerateContentConfig(
                temperature=0.3,  # ì •í™•í•œ ë³€í™˜ì„ ìœ„í•´ ë‚®ì€ temperature
                max_output_tokens=65536,
            ),
        )

        result = response.text
        if not result:
            print("âš ï¸  MDX ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None

        # ìë™ ê²€ì¦/ìˆ˜ì •
        sanitized, fixes = sanitize_mdx(result)
        if fixes:
            print(f"ğŸ”§ ìë™ ìˆ˜ì • {len(fixes)}ê±´:")
            for f in fixes[:10]:
                print(f"   â€¢ {f}")
            if len(fixes) > 10:
                print(f"   ... ì™¸ {len(fixes) - 10}ê±´")
        else:
            print("âœ… MDX ê²€ì¦ í†µê³¼ â€” ìˆ˜ì • ë¶ˆí•„ìš”")

        # ë‹¨ì–´ ìˆ˜ í™•ì¸
        word_count = len(sanitized.split())
        print(f"   ë‹¨ì–´ ìˆ˜: ~{word_count:,}")

        return sanitized

    except Exception as e:
        print(f"âš ï¸  MDX ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None


def save_mdx(content: str, slug: str) -> Path:
    """MDX íŒŒì¼ì„ content/deep-dive/ì— ì €ì¥í•©ë‹ˆë‹¤."""
    DEEP_DIVE_DIR.mkdir(parents=True, exist_ok=True)
    # slugì— -2026ì´ ì•ˆ ë¶™ì–´ìˆìœ¼ë©´ ì¶”ê°€
    if not slug.endswith("-2026"):
        filename = f"{slug}-2026.md"
    else:
        filename = f"{slug}.md"
    filepath = DEEP_DIVE_DIR / filename
    filepath.write_text(content, encoding="utf-8")
    print(f"ğŸ’¾ MDX ì €ì¥: content/deep-dive/{filename}")
    return filepath


def process_item(
    num: int,
    items: dict,
    api_key: str,
    dry_run: bool = False,
    stream: bool = True,
    no_image: bool = False,
    image_only: bool = False,
    no_convert: bool = False,
    convert_only: bool = False,
):
    """í•˜ë‚˜ì˜ ì£¼ì œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if num not in items:
        print(f"âŒ #{num}ë²ˆì€ todo.mdì— ì—†ìŠµë‹ˆë‹¤.")
        return False

    item = items[num]
    filepath = get_draft_filepath(num, items)
    slug = make_slug(item["topic"])

    print(f"\n{'='*60}")
    print(f"ğŸ“ #{num}. [{item['code']}] {item['topic']}")
    print(f"   ì¹´í…Œê³ ë¦¬: {item['category']}")
    print(f"   íŒŒì¼: {filepath.name}")
    print(f"   ìŠ¬ëŸ¬ê·¸: {slug}")
    print(f"{'='*60}")

    # --convert-only: ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ MDX ë³€í™˜ë§Œ ì‹¤í–‰
    if convert_only:
        if not filepath.exists() or filepath.stat().st_size < 500:
            print(f"âŒ ë“œë˜í”„íŠ¸ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            return False
        draft_text = filepath.read_text(encoding="utf-8")
        # ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
        img_path = IMAGES_DIR / f"{slug}.webp"
        image_rel = f"/images/deep-dive/{slug}.webp" if img_path.exists() else None
        if dry_run:
            prompt = build_conversion_prompt(draft_text, item["category"], slug, image_rel, time.strftime("%Y-%m-%d"))
            print(f"\nğŸ” [DRY RUN] MDX ë³€í™˜ í”„ë¡¬í”„íŠ¸ ({len(prompt):,}ì)")
            print(f"   deepDiveOrder: {get_next_deep_dive_order()}")
            print(f"   ì´ë¯¸ì§€: {image_rel or 'ì—†ìŒ'}")
            return True
        mdx_content = convert_to_mdx(draft_text, item["category"], slug, image_rel, api_key)
        if mdx_content:
            save_mdx(mdx_content, slug)
        return mdx_content is not None

    # --image-only: ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ ì´ë¯¸ì§€ë§Œ ìƒì„±
    if image_only:
        if not filepath.exists() or filepath.stat().st_size < 500:
            print(f"âŒ ë“œë˜í”„íŠ¸ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            return False
        draft_text = filepath.read_text(encoding="utf-8")
        elements = parse_cover_image_elements(draft_text)
        if not elements:
            print(f"âš ï¸  COVER IMAGE ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        if dry_run:
            prompt = COVER_IMAGE_TEMPLATE.format(
                short_title=elements["short_title"],
                category=item["category"],
                scene=elements["scene"],
                key_objects=elements["key_objects"],
                mood=elements["mood"],
                color_palette=elements["color_palette"],
            )
            print(f"\nğŸ” [DRY RUN] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ({len(prompt):,}ì):")
            print("-" * 40)
            print(prompt)
            print("-" * 40)
            return True
        generate_cover_image(elements, item["category"], slug, api_key)
        return True

    # ì´ë¯¸ ë‚´ìš©ì´ ìˆëŠ” íŒŒì¼ ìŠ¤í‚µ
    if filepath.exists() and filepath.stat().st_size > 500:
        print(f"â­ï¸  ì´ë¯¸ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤ ({filepath.stat().st_size:,} bytes). ìŠ¤í‚µ.")
        return True

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = build_prompt(item["topic"], item["category"])

    if dry_run:
        print(f"\nğŸ” [DRY RUN] í”„ë¡¬í”„íŠ¸ ({len(prompt):,}ì):")
        print("-" * 40)
        # í”„ë¡¬í”„íŠ¸ì˜ ì²˜ìŒê³¼ ë§ˆì§€ë§‰ í‘œì‹œ
        print(prompt[:500])
        print("...")
        print(prompt[-300:])
        print("-" * 40)
        return True

    # Deep Research ì‹¤í–‰
    try:
        if stream:
            result = run_deep_research_streaming(prompt, api_key)
        else:
            result = run_deep_research(prompt, api_key)
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return False

    # ê²°ê³¼ ì €ì¥
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(result)

    print(f"ğŸ’¾ ì €ì¥: {filepath.name} ({len(result):,}ì)")

    # ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„±
    image_rel_path = None
    if not no_image:
        elements = parse_cover_image_elements(result)
        if elements:
            img_result = generate_cover_image(elements, item["category"], slug, api_key)
            if img_result:
                image_rel_path = f"/images/deep-dive/{slug}.webp"
        else:
            print("âš ï¸  COVER IMAGE ì„¹ì…˜ì´ ì—†ì–´ ì´ë¯¸ì§€ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # MDX ë³€í™˜
    if not no_convert:
        mdx_content = convert_to_mdx(result, item["category"], slug, image_rel_path, api_key)
        if mdx_content:
            save_mdx(mdx_content, slug)
            print(f"\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ë“œë˜í”„íŠ¸ â†’ ì´ë¯¸ì§€ â†’ MDX")
        else:
            print(f"\nâš ï¸  MDX ë³€í™˜ ì‹¤íŒ¨. ë“œë˜í”„íŠ¸ëŠ” ì €ì¥ë˜ì–´ ìˆìœ¼ë‹ˆ --convert-onlyë¡œ ì¬ì‹œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    return True


# ============================================================
# ê¸°ì¡´ Deep-Dive MDXì— ì»¤ë²„ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„± (Backfill)
# ============================================================

COVER_ELEMENTS_PROMPT = """You are a creative director for "Korea Experience", a premium Korea travel blog.

Given a blog post's title, excerpt, and category, generate COVER IMAGE elements for an AI image generator.

RULES:
- Short Title: 2-5 words, ALL CAPS, punchy magazine-style headline. Max 30 characters.
- Scene: 1-2 sentences describing a vivid, photographic scene that captures the article's essence. Be specific to Korea.
- Key Objects: 3-5 concrete visual elements that should appear in the image, comma-separated.
- Mood: One or two words describing the feeling (e.g., "vibrant", "serene and elegant", "dramatic").
- Color Palette: 2-3 color descriptions (e.g., "warm amber, deep navy, cherry blossom pink").

Output EXACTLY this format (no extra text):
Short Title: [YOUR TITLE]
Scene: [YOUR SCENE]
Key Objects: [YOUR OBJECTS]
Mood: [YOUR MOOD]
Color Palette: [YOUR COLORS]

---
Title: "{title}"
Excerpt: "{excerpt}"
Category: {category}
"""


def generate_cover_elements(title: str, excerpt: str, category: str, api_key: str) -> dict | None:
    """Gemini Proë¡œ ì»¤ë²„ ì´ë¯¸ì§€ ìš”ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    prompt = COVER_ELEMENTS_PROMPT.format(title=title, excerpt=excerpt, category=category)

    try:
        response = client.models.generate_content(
            model=COVER_MODEL,
            contents=[prompt],
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=500,
            ),
        )

        text = response.text
        if not text:
            return None

        # íŒŒì‹±
        def extract(name: str) -> str:
            m = re.search(rf"{name}:\s*(.+)", text, re.IGNORECASE)
            return m.group(1).strip().strip('"\'') if m else ""

        short_title = extract("Short Title")
        scene = extract("Scene")
        key_objects = extract("Key Objects")
        mood = extract("Mood")
        color_palette = extract("Color Palette")

        if not scene or not short_title:
            return None

        return {
            "short_title": short_title,
            "scene": scene,
            "key_objects": key_objects or "Korean cityscape",
            "mood": mood or "vibrant",
            "color_palette": color_palette or "warm tones, soft blue",
        }

    except Exception as e:
        print(f"   âš ï¸  ìš”ì†Œ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def backfill_covers(api_key: str, dry_run: bool = False, limit: int = 0):
    """ê¸°ì¡´ deep-dive MDX íŒŒì¼ì— ì»¤ë²„ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"\n{'='*60}")
    print(f"ğŸ–¼ï¸  ê¸°ì¡´ Deep-Dive ì»¤ë²„ ì´ë¯¸ì§€ Backfill")
    print(f"{'='*60}")

    if not DEEP_DIVE_DIR.exists():
        print("âŒ content/deep-dive/ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # image í•„ë“œê°€ ì—†ëŠ” MDX íŒŒì¼ ì°¾ê¸°
    targets = []
    for md_file in sorted(DEEP_DIVE_DIR.glob("*.md")):
        content = md_file.read_text(encoding="utf-8")
        # frontmatterì—ì„œ image í•„ë“œ í™•ì¸
        fm_match = re.match(r"---\n(.*?)\n---", content, re.DOTALL)
        if not fm_match:
            continue
        frontmatter = fm_match.group(1)

        if re.search(r"^image:", frontmatter, re.MULTILINE):
            continue  # ì´ë¯¸ ì´ë¯¸ì§€ê°€ ìˆìŒ

        # title, excerpt, category ì¶”ì¶œ
        title_m = re.search(r'^title:\s*"?(.+?)"?\s*$', frontmatter, re.MULTILINE)
        excerpt_m = re.search(r'^excerpt:\s*"?(.+?)"?\s*$', frontmatter, re.MULTILINE)
        category_m = re.search(r'^category:\s*(.+)$', frontmatter, re.MULTILINE)

        if not title_m or not category_m:
            continue

        slug = md_file.stem  # e.g., "why-google-maps-doesnt-work-in-korea"
        targets.append({
            "file": md_file,
            "slug": slug,
            "title": title_m.group(1).strip(),
            "excerpt": excerpt_m.group(1).strip() if excerpt_m else "",
            "category": category_m.group(1).strip(),
        })

    print(f"ğŸ“‹ ì´ë¯¸ì§€ ì—†ëŠ” íŒŒì¼: {len(targets)}ê°œ")

    if limit > 0:
        targets = targets[:limit]
        print(f"   (--backfill-limit {limit} ì ìš©)")

    if not targets:
        print("âœ… ëª¨ë“  íŒŒì¼ì— ì´ë¯¸ì§€ê°€ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤!")
        return

    for i, t in enumerate(targets):
        print(f"\n[{i+1}/{len(targets)}] {t['slug']}")

    if dry_run:
        print(f"\nğŸ” [DRY RUN] {len(targets)}ê°œ íŒŒì¼ì— ëŒ€í•´ ì»¤ë²„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        for t in targets:
            print(f"   â€¢ {t['slug']} ({t['category']})")
            print(f"     Title: {t['title'][:60]}...")
        return

    # ì²˜ë¦¬ ì‹œì‘
    success = 0
    failed = 0
    for i, t in enumerate(targets):
        print(f"\n{'â”€'*50}")
        print(f"[{i+1}/{len(targets)}] {t['slug']}")
        print(f"   ì œëª©: {t['title'][:60]}")
        print(f"   ì¹´í…Œê³ ë¦¬: {t['category']}")

        # 1. Gemini Proë¡œ ì»¤ë²„ ì´ë¯¸ì§€ ìš”ì†Œ ìƒì„±
        print(f"   ğŸ¤– ì»¤ë²„ ìš”ì†Œ ìƒì„± ì¤‘...")
        elements = generate_cover_elements(t["title"], t["excerpt"], t["category"], api_key)
        if not elements:
            print(f"   âŒ ìš”ì†Œ ìƒì„± ì‹¤íŒ¨ â€” ìŠ¤í‚µ")
            failed += 1
            continue

        print(f"   Short Title: \"{elements['short_title']}\"")
        print(f"   Scene: {elements['scene'][:60]}...")

        # 2. Nano Banana Proë¡œ ì´ë¯¸ì§€ ìƒì„±
        img_path = generate_cover_image(elements, t["category"], t["slug"], api_key)
        if not img_path:
            print(f"   âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ â€” ìŠ¤í‚µ")
            failed += 1
            continue

        # 3. MDX frontmatterì— image í•„ë“œ ì¶”ê°€
        image_rel = f"/images/deep-dive/{t['slug']}.webp"
        content = t["file"].read_text(encoding="utf-8")
        # author: ì¤„ ë’¤ì— image ì¶”ê°€ (ë˜ëŠ” deepDiveOrder ë’¤ì—)
        updated = re.sub(
            r"(deepDiveOrder:\s*\d+)",
            r'\1\nimage: "' + image_rel + r'"',
            content,
            count=1,
        )
        if updated == content:
            # deepDiveOrderê°€ ì—†ìœ¼ë©´ author ë’¤ì—
            updated = re.sub(
                r"(author:\s*.+)",
                r'\1\nimage: "' + image_rel + r'"',
                content,
                count=1,
            )

        t["file"].write_text(updated, encoding="utf-8")
        print(f"   âœ… frontmatter ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        success += 1

        # Rate limit ë°©ì§€ â€” 5ì´ˆ ëŒ€ê¸°
        if i < len(targets) - 1:
            print(f"   â³ 5ì´ˆ ëŒ€ê¸°...")
            time.sleep(5)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š Backfill ì™„ë£Œ: âœ… {success} / âŒ {failed} / ì „ì²´ {len(targets)}")
    print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(description="Deep Dive Content Generator (Gemini Deep Research API)")
    parser.add_argument("--number", "-n", type=int, help="ì²˜ë¦¬í•  ì£¼ì œ ë²ˆí˜¸")
    parser.add_argument("--from", dest="from_num", type=int, help="ë°°ì¹˜ ì‹œì‘ ë²ˆí˜¸")
    parser.add_argument("--to", dest="to_num", type=int, help="ë°°ì¹˜ ì¢…ë£Œ ë²ˆí˜¸")
    parser.add_argument("--dry-run", action="store_true", help="API í˜¸ì¶œ ì—†ì´ í”„ë¡¬í”„íŠ¸ë§Œ í™•ì¸")
    parser.add_argument("--no-stream", action="store_true", help="ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™” (í´ë§ ëª¨ë“œ)")
    parser.add_argument("--no-image", action="store_true", help="ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„± ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--image-only", action="store_true", help="ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ ì»¤ë²„ ì´ë¯¸ì§€ë§Œ ìƒì„±")
    parser.add_argument("--no-convert", action="store_true", help="MDX ë³€í™˜ ê±´ë„ˆë›°ê¸° (ë“œë˜í”„íŠ¸+ì´ë¯¸ì§€ë§Œ)")
    parser.add_argument("--convert-only", action="store_true", help="ê¸°ì¡´ ë“œë˜í”„íŠ¸ì—ì„œ MDX ë³€í™˜ë§Œ ì‹¤í–‰")
    parser.add_argument("--backfill-covers", action="store_true", help="ê¸°ì¡´ deep-dive MDXì— ì»¤ë²„ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±")
    parser.add_argument("--backfill-limit", type=int, default=0, help="backfill ì‹œ ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (0=ì „ì²´)")
    args = parser.parse_args()

    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key and not args.dry_run:
        print("âŒ GEMINI_API_KEYê°€ .env.localì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # --backfill-covers ëª¨ë“œ
    if args.backfill_covers:
        backfill_covers(api_key, args.dry_run, args.backfill_limit)
        return

    items = parse_todo()
    print(f"ğŸ“‹ todo.mdì—ì„œ {len(items)}ê°œ ì£¼ì œ ë¡œë“œ")

    use_stream = not args.no_stream

    if args.from_num and args.to_num:
        # ë°°ì¹˜ ëª¨ë“œ
        success = 0
        for num in range(args.from_num, args.to_num + 1):
            if process_item(num, items, api_key, args.dry_run, use_stream, args.no_image, args.image_only, args.no_convert, args.convert_only):
                success += 1
        print(f"\nğŸ“Š ë°°ì¹˜ ì™„ë£Œ: {success}/{args.to_num - args.from_num + 1}")

    elif args.number:
        # ë‹¨ì¼ ë²ˆí˜¸
        process_item(args.number, items, api_key, args.dry_run, use_stream, args.no_image, args.image_only, args.no_convert, args.convert_only)

    else:
        # ìë™ ê°ì§€
        next_num = find_next_number(items)
        if next_num is None:
            print("âœ… ëª¨ë“  ì£¼ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"ğŸ¯ ë‹¤ìŒ ì£¼ì œ: #{next_num}")
            process_item(next_num, items, api_key, args.dry_run, use_stream, args.no_image, args.image_only, args.no_convert, args.convert_only)


if __name__ == "__main__":
    main()
