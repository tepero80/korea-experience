"""
Deep Dive ì „ì²´ íŒŒì´í”„ë¼ì¸ CLI
===============================
Deep Research â†’ ì»¤ë²„ ì´ë¯¸ì§€ â†’ MDX ë³€í™˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

Usage:
  # ìë™ ê°ì§€ (ë‹¤ìŒ ë¯¸ì™„ë£Œ ë²ˆí˜¸)
  python -m scripts.deep_dive.generate

  # íŠ¹ì • ë²ˆí˜¸
  python -m scripts.deep_dive.generate -n 39

  # ë°°ì¹˜ (ë²”ìœ„)
  python -m scripts.deep_dive.generate --from 39 --to 50

  # ì˜µì…˜ë³„ ì‹¤í–‰
  python -m scripts.deep_dive.generate -n 39 --dry-run
  python -m scripts.deep_dive.generate -n 39 --image-only
  python -m scripts.deep_dive.generate -n 39 --convert-only
  python -m scripts.deep_dive.generate -n 39 --no-image
  python -m scripts.deep_dive.generate -n 39 --no-convert

  # ê¸°ì¡´ MDXì— ì»¤ë²„ ì´ë¯¸ì§€ ì¼ê´„ ìƒì„±
  python -m scripts.deep_dive.generate --backfill-covers
"""

import argparse
import os
import re
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from scripts.deep_dive.config import (
    API_KEY, DRAFTS_DIR, IMAGES_DIR, DEEP_DIVE_DIR,
    IMAGE_MODEL, COVER_IMAGE_TEMPLATE,
    CATEGORY_VISUAL_HINTS,
)
from scripts.deep_dive.topics import (
    parse_todo, find_next_number, get_existing_slugs, get_next_deep_dive_order,
    update_status, STEP_RESEARCH, STEP_IMAGE, STEP_CONVERT,
)
from scripts.deep_dive.research import (
    build_prompt, run_deep_research, run_deep_research_streaming,
)
from scripts.deep_dive.convert import (
    convert_to_mdx, save_mdx, build_conversion_prompt,
)
from scripts.deep_dive.cover import generate_cover
from scripts.deep_dive.links import refresh_index


# â”€â”€ ë“œë˜í”„íŠ¸ ì»¤ë²„ ì´ë¯¸ì§€ (ì›ë³¸ ë°©ì‹ â€” Gemini í…ìŠ¤íŠ¸ ë Œë”ë§) â”€â”€

def parse_cover_image_elements(draft_text: str) -> dict | None:
    """ë“œë˜í”„íŠ¸ì—ì„œ COVER IMAGE ì„¹ì…˜ì˜ ìš”ì†Œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    cover_match = re.search(
        r"##\s*COVER\s*IMAGE.*?\n(.*?)(?=\n##\s|\Z)",
        draft_text, re.DOTALL | re.IGNORECASE,
    )
    if not cover_match:
        cover_match = re.search(
            r"COVER\s*IMAGE\s*\n(.*?)(?=\n(?:OPTIONAL|SOURCES|ARTICLE|LOCATIONS|PRICE|KEY STAT|ROUTE)|\Z)",
            draft_text, re.DOTALL | re.IGNORECASE,
        )
    if not cover_match:
        return None

    section = cover_match.group(1)

    def extract_field(name: str) -> str:
        patterns = [
            rf"\*\*{name}:\*\*\s*(.+?)(?=\n\*\*|\n---|\Z)",
            rf"{name}:\s*(.+?)(?=\n[A-Z]|\n\*\*|\n---|\Z)",
        ]
        for pat in patterns:
            m = re.search(pat, section, re.IGNORECASE | re.DOTALL)
            if m:
                return m.group(1).strip().strip('"\'')
        return ""

    scene = extract_field("Scene")
    if not scene:
        return None

    return {
        "short_title": extract_field("Short Title") or "Korea Guide",
        "scene": scene,
        "key_objects": extract_field("Key Objects") or "Korean cityscape",
        "mood": extract_field("Mood") or "vibrant",
        "color_palette": extract_field("Color Palette") or "warm tones, soft blue",
    }


def generate_legacy_cover(elements: dict, category: str, slug: str, api_key: str) -> Path | None:
    """ê¸°ì¡´ ë°©ì‹: Gemini Image Modelì—ê²Œ í…ìŠ¤íŠ¸ í¬í•¨ ì´ë¯¸ì§€ ì§ì ‘ ìƒì„±"""
    from google import genai
    from google.genai import types
    from PIL import Image as PILImage
    import tempfile

    client = genai.Client(api_key=api_key)
    prompt = COVER_IMAGE_TEMPLATE.format(
        short_title=elements["short_title"],
        category=category,
        scene=elements["scene"],
        key_objects=elements["key_objects"],
        mood=elements["mood"],
        color_palette=elements["color_palette"],
    )

    print(f"\nğŸ¨ ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    print(f"   Short Title: \"{elements['short_title']}\"")

    try:
        response = client.models.generate_content(
            model=IMAGE_MODEL,
            contents=[prompt],
            config=types.GenerateContentConfig(response_modalities=["IMAGE"]),
        )

        IMAGES_DIR.mkdir(parents=True, exist_ok=True)
        output_path = IMAGES_DIR / f"{slug}.webp"

        for part in response.parts:
            if part.inline_data is not None:
                image = part.as_image()
                with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
                    tmp_path = tmp.name
                image.save(tmp_path)
                PILImage.open(tmp_path).save(str(output_path), format="WEBP", quality=85)
                Path(tmp_path).unlink(missing_ok=True)
                print(f"âœ… ì €ì¥: {output_path.name}")
                return output_path

        return None
    except Exception as e:
        print(f"âš ï¸  ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def make_slug(topic: str) -> str:
    """í† í”½ ì´ë¦„ì—ì„œ íŒŒì¼ëª…ìš© slugë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    slug = topic.lower().strip()
    slug = re.sub(r"[^a-z0-9\s-]", "", slug)
    slug = re.sub(r"[\s_]+", "-", slug)
    slug = re.sub(r"-+", "-", slug).strip("-")
    if len(slug) > 60:
        slug = slug[:60].rsplit("-", 1)[0]
    return slug


def get_draft_filepath(num: int, items: dict) -> Path:
    """ë“œë˜í”„íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    existing = list(DRAFTS_DIR.glob(f"{num}.*txt"))
    if existing:
        return existing[0]
    item = items[num]
    filename = f"{num}. [{item['code']}] {item['topic']}.txt"
    return DRAFTS_DIR / filename


# â”€â”€ ë©”ì¸ ì²˜ë¦¬ â”€â”€

def process_item(num, items, api_key, dry_run=False, stream=True,
                 no_image=False, image_only=False, no_convert=False, convert_only=False):
    """í•˜ë‚˜ì˜ ì£¼ì œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if num not in items:
        print(f"âŒ #{num}ë²ˆì€ todo.mdì— ì—†ìŠµë‹ˆë‹¤.")
        return False

    item = items[num]
    filepath = get_draft_filepath(num, items)
    slug = make_slug(item["topic"])

    print(f"\n{'='*60}")
    print(f"ğŸ“ #{num}. [{item['code']}] {item['topic']}")
    print(f"   ì¹´í…Œê³ ë¦¬: {item['category']}")
    print(f"   ìŠ¬ëŸ¬ê·¸: {slug}")
    print(f"{'='*60}")

    # --convert-only
    if convert_only:
        if not filepath.exists() or filepath.stat().st_size < 500:
            print(f"âŒ ë“œë˜í”„íŠ¸ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            update_status(num, error="draft file missing or too short")
            return False
        draft_text = filepath.read_text(encoding="utf-8")
        img_path = IMAGES_DIR / f"{slug}.webp"
        image_rel = f"/images/deep-dive/{slug}.webp" if img_path.exists() else None
        if dry_run:
            print(f"\nğŸ” [DRY RUN] deepDiveOrder: {get_next_deep_dive_order()}, ì´ë¯¸ì§€: {image_rel or 'ì—†ìŒ'}")
            return True
        mdx_content = convert_to_mdx(draft_text, item["category"], slug, image_rel, api_key,
                                       topic=item["topic"])
        if mdx_content:
            save_mdx(mdx_content, slug)
            update_status(num, add_step=STEP_CONVERT)
            refresh_index()  # ìƒˆ í¬ìŠ¤íŠ¸ ë°˜ì˜
        else:
            update_status(num, error="mdx conversion failed")
        return mdx_content is not None

    # --image-only
    if image_only:
        if not filepath.exists() or filepath.stat().st_size < 500:
            print(f"âŒ ë“œë˜í”„íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            update_status(num, error="draft file missing")
            return False
        draft_text = filepath.read_text(encoding="utf-8")
        elements = parse_cover_image_elements(draft_text)
        if not elements:
            print(f"âš ï¸  COVER IMAGE ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            update_status(num, error="no COVER IMAGE section")
            return False
        if dry_run:
            print(f"\nğŸ” [DRY RUN] Short Title: \"{elements['short_title']}\"")
            return True
        # Pillow ì˜¤ë²„ë ˆì´ ë°©ì‹ ì‚¬ìš©
        result = generate_cover(slug, item["topic"], item["category"])
        if result:
            update_status(num, add_step=STEP_IMAGE)
        else:
            update_status(num, error="image generation failed")
        return result is not None

    # ê¸°ì¡´ ë“œë˜í”„íŠ¸ í™•ì¸
    if filepath.exists() and filepath.stat().st_size > 500:
        print(f"â­ï¸  ë“œë˜í”„íŠ¸ ì´ë¯¸ ì¡´ì¬ ({filepath.stat().st_size:,} bytes). ë¦¬ì„œì¹˜ ìŠ¤í‚µ.")
        result = filepath.read_text(encoding="utf-8")
        update_status(num, add_step=STEP_RESEARCH)
    else:
        prompt = build_prompt(item["topic"], item["category"])

        if dry_run:
            print(f"\nğŸ” [DRY RUN] í”„ë¡¬í”„íŠ¸ ({len(prompt):,}ì)")
            print(prompt[:500])
            print("...")
            return True

        # Deep Research ì‹¤í–‰
        try:
            result = (run_deep_research_streaming if stream else run_deep_research)(prompt, api_key)
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {e}")
            update_status(num, error=f"research failed: {e}")
            return False

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(result)
        print(f"ğŸ’¾ ì €ì¥: {filepath.name} ({len(result):,}ì)")
        update_status(num, add_step=STEP_RESEARCH)

    # ì»¤ë²„ ì´ë¯¸ì§€ â€” Pillow ì˜¤ë²„ë ˆì´ ë°©ì‹
    image_rel_path = None
    if not no_image:
        img_path = IMAGES_DIR / f"{slug}.webp"
        if img_path.exists() and img_path.stat().st_size > 1000:
            print(f"â­ï¸  ì»¤ë²„ ì´ë¯¸ì§€ ì´ë¯¸ ì¡´ì¬ ({img_path.stat().st_size // 1024}KB). ìŠ¤í‚µ.")
            image_rel_path = f"/images/deep-dive/{slug}.webp"
            update_status(num, add_step=STEP_IMAGE)
        else:
            img_result = generate_cover(slug, item["topic"], item["category"])
            if img_result:
                image_rel_path = f"/images/deep-dive/{slug}.webp"
                update_status(num, add_step=STEP_IMAGE)
            else:
                print("âš ï¸  ì»¤ë²„ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨.")
                update_status(num, error="image generation failed")

    # MDX ë³€í™˜
    if not no_convert:
        mdx_slug = f"{slug}-2026" if not slug.endswith("-2026") else slug
        mdx_path = DEEP_DIVE_DIR / f"{mdx_slug}.md"
        if mdx_path.exists() and mdx_path.stat().st_size > 1000:
            print(f"â­ï¸  MDX íŒŒì¼ ì´ë¯¸ ì¡´ì¬ ({mdx_path.stat().st_size // 1024}KB). ìŠ¤í‚µ.")
            update_status(num, add_step=STEP_CONVERT)
        else:
            mdx_content = convert_to_mdx(result, item["category"], slug, image_rel_path, api_key,
                                         topic=item["topic"])
            if mdx_content:
                save_mdx(mdx_content, slug)
                update_status(num, add_step=STEP_CONVERT)
                refresh_index()  # ìƒˆ í¬ìŠ¤íŠ¸ ë°˜ì˜
                print(f"\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            else:
                print(f"\nâš ï¸  MDX ë³€í™˜ ì‹¤íŒ¨. --convert-onlyë¡œ ì¬ì‹œë„ ê°€ëŠ¥.")
                update_status(num, error="mdx conversion failed")

    return True


# â”€â”€ Backfill â”€â”€

COVER_ELEMENTS_PROMPT = """You are a creative director for "Korea Experience", a premium Korea travel blog.
Given a blog post's title, excerpt, and category, generate COVER IMAGE elements.

Output EXACTLY this format:
Short Title: [2-5 words, punchy headline]
Scene: [1-2 sentences, vivid photographic scene specific to Korea]
Key Objects: [3-5 concrete visual elements, comma-separated]
Mood: [1-2 words]
Color Palette: [2-3 color descriptions]

---
Title: "{title}"
Excerpt: "{excerpt}"
Category: {category}
"""


def backfill_covers(api_key, dry_run=False, limit=0):
    """ê¸°ì¡´ deep-dive MDXì— ì»¤ë²„ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤."""
    from google import genai
    from google.genai import types

    print(f"\nğŸ–¼ï¸  Deep-Dive ì»¤ë²„ ì´ë¯¸ì§€ Backfill\n{'='*60}")

    targets = []
    for md_file in sorted(DEEP_DIVE_DIR.glob("*.md")):
        content = md_file.read_text(encoding="utf-8")
        fm_match = re.match(r"---\n(.*?)\n---", content, re.DOTALL)
        if not fm_match:
            continue
        fm = fm_match.group(1)
        if re.search(r"^image:", fm, re.MULTILINE):
            continue

        title_m = re.search(r'^title:\s*"?(.+?)"?\s*$', fm, re.MULTILINE)
        excerpt_m = re.search(r'^excerpt:\s*"?(.+?)"?\s*$', fm, re.MULTILINE)
        category_m = re.search(r'^category:\s*(.+)$', fm, re.MULTILINE)
        if not title_m or not category_m:
            continue

        targets.append({
            "file": md_file, "slug": md_file.stem,
            "title": title_m.group(1).strip(),
            "excerpt": excerpt_m.group(1).strip() if excerpt_m else "",
            "category": category_m.group(1).strip(),
        })

    if limit > 0:
        targets = targets[:limit]

    print(f"ğŸ“‹ ì´ë¯¸ì§€ ì—†ëŠ” íŒŒì¼: {len(targets)}ê°œ")
    if not targets:
        print("âœ… ëª¨ë“  íŒŒì¼ì— ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤!")
        return

    if dry_run:
        for t in targets:
            print(f"   â€¢ {t['slug']} ({t['category']})")
        return

    success = failed = 0
    for i, t in enumerate(targets):
        print(f"\n[{i+1}/{len(targets)}] {t['slug']}")

        # Pillow ì˜¤ë²„ë ˆì´ ë°©ì‹ìœ¼ë¡œ ìƒì„±
        img_result = generate_cover(t["slug"], t["title"], t["category"], t["excerpt"])
        if not img_result:
            failed += 1
            continue

        # frontmatterì— image ì¶”ê°€
        image_rel = f"/images/deep-dive/{t['slug']}.webp"
        content = t["file"].read_text(encoding="utf-8")
        updated = re.sub(
            r"(deepDiveOrder:\s*\d+)",
            r'\1\nimage: "' + image_rel + r'"',
            content, count=1,
        )
        if updated == content:
            updated = re.sub(
                r"(author:\s*.+)",
                r'\1\nimage: "' + image_rel + r'"',
                content, count=1,
            )
        t["file"].write_text(updated, encoding="utf-8")
        print(f"   âœ… frontmatter ì—…ë°ì´íŠ¸")
        success += 1

        if i < len(targets) - 1:
            time.sleep(5)

    print(f"\nğŸ“Š Backfill ì™„ë£Œ: âœ… {success} / âŒ {failed} / ì „ì²´ {len(targets)}")


# â”€â”€ CLI â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="Deep Dive Content Generator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‹¤í–‰ ëª¨ë“œ:
  python -m scripts.deep_dive -n 39                 # íŠ¹ì • ë²ˆí˜¸ 1ê°œ
  python -m scripts.deep_dive --from 39 --to 50     # ë²”ìœ„ ì§€ì •
  python -m scripts.deep_dive -c 10                  # ë‹¤ìŒ ë¯¸ì™„ë£Œ 10ê°œ
  python -m scripts.deep_dive --all                  # ë¯¸ì™„ë£Œ ì „ì²´
  python -m scripts.deep_dive                        # ë‹¤ìŒ ë¯¸ì™„ë£Œ 1ê°œ (ê¸°ë³¸)

ì˜µì…˜ ì¡°í•©:
  python -m scripts.deep_dive -c 5 --dry-run         # ë‹¤ìŒ 5ê°œ í™•ì¸ë§Œ
  python -m scripts.deep_dive -n 39 --image-only     # ì´ë¯¸ì§€ë§Œ ìƒì„±
  python -m scripts.deep_dive --all --convert-only    # ì „ì²´ MDX ì¬ë³€í™˜
  python -m scripts.deep_dive --backfill-covers       # ì»¤ë²„ ì¼ê´„ ìƒì„±
        """,
    )
    # ì‹¤í–‰ ëª¨ë“œ
    mode = parser.add_argument_group("ì‹¤í–‰ ëª¨ë“œ (íƒ1)")
    mode.add_argument("--number", "-n", type=int, help="íŠ¹ì • ì£¼ì œ ë²ˆí˜¸ 1ê°œ ì²˜ë¦¬")
    mode.add_argument("--from", dest="from_num", type=int, help="ë°°ì¹˜ ì‹œì‘ ë²ˆí˜¸")
    mode.add_argument("--to", dest="to_num", type=int, help="ë°°ì¹˜ ì¢…ë£Œ ë²ˆí˜¸")
    mode.add_argument("--count", "-c", type=int, help="ë‹¤ìŒ ë¯¸ì™„ë£Œ Nê°œ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬")
    mode.add_argument("--all", action="store_true", help="ë¯¸ì™„ë£Œ ì „ì²´ ì²˜ë¦¬")

    # íŒŒì´í”„ë¼ì¸ ì˜µì…˜
    pipe = parser.add_argument_group("íŒŒì´í”„ë¼ì¸ ì˜µì…˜")
    pipe.add_argument("--dry-run", action="store_true", help="API í˜¸ì¶œ ì—†ì´ í™•ì¸ë§Œ")
    pipe.add_argument("--no-stream", action="store_true", help="í´ë§ ëª¨ë“œ (ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹ )")
    pipe.add_argument("--no-image", action="store_true", help="ì»¤ë²„ ì´ë¯¸ì§€ ê±´ë„ˆë›°ê¸°")
    pipe.add_argument("--image-only", action="store_true", help="ì´ë¯¸ì§€ë§Œ ìƒì„±")
    pipe.add_argument("--no-convert", action="store_true", help="MDX ë³€í™˜ ê±´ë„ˆë›°ê¸°")
    pipe.add_argument("--convert-only", action="store_true", help="MDX ë³€í™˜ë§Œ")
    pipe.add_argument("--backfill-covers", action="store_true", help="ê¸°ì¡´ MDXì— ì»¤ë²„ ì¼ê´„ ìƒì„±")
    pipe.add_argument("--backfill-limit", type=int, default=0, help="backfill ìµœëŒ€ ì²˜ë¦¬ ìˆ˜")
    args = parser.parse_args()

    api_key = API_KEY
    if not api_key and not args.dry_run:
        print("âŒ GEMINI_API_KEYê°€ .env.localì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    if args.backfill_covers:
        backfill_covers(api_key, args.dry_run, args.backfill_limit)
        return

    items = parse_todo()
    done_count = sum(1 for i in items.values() if i.get("status") == "done")
    print(f"ğŸ“‹ todo.md: {len(items)}ê°œ ì£¼ì œ ({done_count} ì™„ë£Œ, {len(items) - done_count} ë‚¨ìŒ)")
    use_stream = not args.no_stream

    # ê³µí†µ kwargs
    kwargs = dict(
        dry_run=args.dry_run, stream=use_stream,
        no_image=args.no_image, image_only=args.image_only,
        no_convert=args.no_convert, convert_only=args.convert_only,
    )

    # â‘  íŠ¹ì • ë²ˆí˜¸
    if args.number:
        process_item(args.number, items, api_key, **kwargs)

    # â‘¡ ë²”ìœ„ ì§€ì •
    elif args.from_num and args.to_num:
        targets = list(range(args.from_num, args.to_num + 1))
        _run_batch(targets, items, api_key, kwargs)

    # â‘¢ ë‹¤ìŒ Nê°œ
    elif args.count:
        targets = _get_pending_numbers(items, args.count)
        if not targets:
            print("âœ… ëª¨ë“  ì£¼ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"ğŸ¯ ë‹¤ìŒ {len(targets)}ê°œ: #{targets[0]}~#{targets[-1]}")
            _run_batch(targets, items, api_key, kwargs)

    # â‘£ ì „ì²´
    elif args.all:
        targets = _get_pending_numbers(items, limit=0)
        if not targets:
            print("âœ… ëª¨ë“  ì£¼ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"ğŸ¯ ë¯¸ì™„ë£Œ ì „ì²´ {len(targets)}ê°œ: #{targets[0]}~#{targets[-1]}")
            _run_batch(targets, items, api_key, kwargs)

    # â‘¤ ê¸°ë³¸: ë‹¤ìŒ 1ê°œ
    else:
        next_num = find_next_number(items)
        if next_num is None:
            print("âœ… ëª¨ë“  ì£¼ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"ğŸ¯ ë‹¤ìŒ ì£¼ì œ: #{next_num}")
            process_item(next_num, items, api_key, **kwargs)


def _get_pending_numbers(items: dict, limit: int = 0) -> list[int]:
    """ë¯¸ì™„ë£Œ ì£¼ì œ ë²ˆí˜¸ë¥¼ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. limit=0ì´ë©´ ì „ì²´."""
    from .topics import STATUS_DONE
    pending = [
        num for num in sorted(items.keys())
        if items[num].get("status") != STATUS_DONE
    ]
    return pending if limit == 0 else pending[:limit]


def _run_batch(targets: list[int], items: dict, api_key: str, kwargs: dict):
    """ë°°ì¹˜ ì‹¤í–‰ ê³µí†µ ë¡œì§."""
    success = failed = skipped = 0
    total = len(targets)
    for i, num in enumerate(targets):
        print(f"\n{'â”€'*60}")
        print(f"ğŸ“¦ [{i+1}/{total}]")
        if num not in items:
            print(f"âš ï¸  #{num}ë²ˆì€ todo.mdì— ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µ.")
            skipped += 1
            continue
        try:
            ok = process_item(num, items, api_key, **kwargs)
            if ok:
                success += 1
            else:
                failed += 1
        except KeyboardInterrupt:
            print(f"\n\nâ›” ì‚¬ìš©ì ì¤‘ë‹¨ (Ctrl+C)")
            print(f"ğŸ“Š ì¤‘ê°„ ê²°ê³¼: âœ… {success} / âŒ {failed} / â­ï¸ {skipped} / ì „ì²´ {total}")
            sys.exit(130)
        except Exception as e:
            print(f"âŒ #{num} ì˜ˆì™¸: {e}")
            failed += 1

    print(f"\n{'â•'*60}")
    print(f"ğŸ“Š ë°°ì¹˜ ì™„ë£Œ: âœ… {success} / âŒ {failed} / â­ï¸ {skipped} / ì „ì²´ {total}")


if __name__ == "__main__":
    main()
